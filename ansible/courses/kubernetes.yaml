module:
  name: k8s-practice-course
  title: Kubernetes Practice
  description: Practical Kubernetes Tasks
  db_name: kubernetes
  courses:
  - course_id: k8s-init
    title: Creating Kubernetes Cluster
    description: Creating multi node Kubernetes cluster with kubeadm
    time: 30 minutes
    steps:
      - title: Welcome
        task: |-
          ## Let us know who you are.

          Please open "**User**" Tab and fill required information

          `touch /.ok`
        verify: |-
          [ -f /opt/.user ]
      - title: Initialize Kubernetes Control Plain
        task: |
          Initialize Master node with `kubeadm`

          ## Parameters:
          - token: abcdef.0123456789abcdef
          - token life duration: 20m

          ## Tips:
          - You can destroy cluster configuration with `kubeadm reset cluster`

          ## Documentation:
          - https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/
        verify: |
          kubectl get nodes >/dev/null 2>&1 &&
          kubeadm token list | grep abcdef.0123456789abcdef >/dev/null &&
          [ `kubeadm token list | grep abcdef.0123456789abcdef | awk '{print $2}' | sed 's/[^0-9]//g'` -le 20 ]
      - title: Configure kubectl utility
        task: |
          Configure current user to operate with kubernetes API with `kubectl`

          ## Requiremets:
          - user: `root`

          ## Documentation:
          - https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/
        verify: |
          kubectl get nodes >/dev/null 2>&1
        foreground: clear
      - title: Deploy POD Network
        task: |
          Deploy `weave` POD Network

          ## Tips:
          - Check that CNI pods are running

          ## Documentation:
          - https://www.weave.works/blog/weave-net-kubernetes-integration/
          - https://www.weave.works/docs/net/latest/kubernetes/kube-addon/
        verify: |
          kubectl get pods -n kube-system | grep weave | grep Running >/dev/null
        foreground: clear
      - title: Join Worker Node
        task: |
          Join `node01` to the cluster 

          ## Tips:
          - Remember token is *abcdef.0123456789abcdef*?
          - Default API Port on master is *6443*
          - Use `ssh node01` to connect to `node01` host
          - Wait till node01 turns to `Ready` state

          ## Documentation:
          - https://www.weave.works/blog/weave-net-kubernetes-integration/
          - https://www.weave.works/docs/net/latest/kubernetes/kube-addon/
        foreground: clear
      - title: Decorate Worker Node with Custom Label
        task: |
          Label node01 as `worker`

          ```
          kubectl get nodes
          NAME     STATUS   ROLES    AGE     VERSION
          master   Ready    master   3m43s   v1.14.0
          node01   Ready    worker   46s     v1.14.0
          ```


          ## Tips:
          - You should just label necessary node as `node-role.kubernetes.io/<< node role >>`

          ## Documentation:
          - http://kubernetesbyexample.com/labels/
          - https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#updating-labels
        verify: |
          kubectl get node node01 --show-labels | grep 'node-role.kubernetes.io/worker=' >/dev/null
      - title: Deploy Kubernetes Dashboard
        task: |
          Deploy Dashboard Manifest from [here](https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml)

          ## Create Admin User

          ```yaml
          apiVersion: v1
          kind: ServiceAccount
          metadata:
            name: admin-user
            namespace: kube-system
          ---
          apiVersion: rbac.authorization.k8s.io/v1beta1
          kind: ClusterRoleBinding
          metadata:
            name: admin-user
          roleRef:
            apiGroup: rbac.authorization.k8s.io
            kind: ClusterRole
            name: cluster-admin
          subjects:
          - kind: ServiceAccount
            name: admin-user
            namespace: kube-system
          ```

          ## Get Admin Secret

          ```
          SECRET_NAME="$(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}')"
          kubectl get secret -n kube-system ${SECRET_NAME} -o jsonpath='{.data.token}' | base64 -d
          ```

          ## Proxy Dashboard

          Expose Dashord from inside cluster with `kubectl proxy` command:

          ```
          kubectl proxy --address='0.0.0.0' --accept-hosts='^*$'
          ```

          ## Explore Kubernetes Cluster on "Dashboard" Tab

          Please use token authentication from previous step

          ## Documentation:
          - https://github.com/kubernetes/dashboard
          - https://github.com/kubernetes/dashboard/wiki/Creating-sample-user
        verify: |
          [ `kubectl get deployment -n kube-system kubernetes-dashboard -o jsonpath='{.spec.template.spec.containers[0].name}'` == "kubernetes-dashboard" ] &&
          [ `kubectl get svc -n kube-system kubernetes-dashboard -o jsonpath='{.spec.ports[0].targetPort}'` == "8443" ] &&
          [ `kubectl get ep -n kube-system kubernetes-dashboard -o jsonpath="{.subsets[*].addresses[0].nodeName}"` == 'node01' ]
      - title: Deploy Metrics-server
        task: |
          Deploy Metrics Server from [here](https://raw.githubusercontent.com/kubernetes/kops/master/addons/metrics-server/v1.8.x.yaml)

          ## Check that:
          - Metrics Server is deployed successfully and is `Running`
          - Command `kubectl top nodes` shows performance statistics by nodes
          - Command `kubectl top pods --all-namespaces` shows performance statistics by pods

          ## Documentation:
          - https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/
          - https://github.com/kubernetes-incubator/metrics-server
        verify: |
          [ `kubectl get pods -n kube-system $(kubectl get pods -n kube-system | grep metrics | awk '{print $1}') -o jsonpath='{.status.phase}'` == "Running" ]
    intro: |
      # In this section you will do following:

      - Initialize Kubernetes Control Plain
      - Configure kubectl utility
      - Depploy POD Network
      - Join Worker Node
      - Decorate Worker Node with Custom Label
      - Deploy Kubernetes Dashboard
      - Deploy Metrics-server


      # Good Luck!
    finish: |
      # It's Done!

      Some useful commands to know:

      <pre class="file">

      kubectl get nodes
      kubectl cluster-info
      kubectl get componentstatus

      kubectl get pods
      kubectl get deployments
      kubectl get svc

      kubectl top nodes
      kubectl top pods 
      kubectl top pods --all-namespaces
      </pre>
    environment:
      hideintro: false
      showdashboards: true
      uilayout: terminal-iframe
      imageid: "kubernetes-cluster"
      dashboards:
        - name: User
          port: 8080
        - name: K8s Dashboard
          port: 8001
  - course_id: k8s-pods
    title: Pod Game
    description: Managing Pods and all about them
    time: 45 minutes
    steps:
      - title: Welcome
        task: |-
          ## Let us know who you are.

          Please open "**User**" Tab and fill required information

          `touch /.ok`
        verify: |-
          [ -f /opt/.user ]
      - title: Simple Pod
        task: |
          ### Create a Pod

          - Deploy a pod named `nginx-pod` using the `nginx:alpine` image
          - Label: `app=nginx`

          ## Documentation:
          - https://kubernetes.io/docs/concepts/workloads/pods/pod/
        verify: |
          [ `kubectl get pods nginx-pod -o jsonpath='{.status.phase}'` == "Running" ] &&
          [ `kubectl get pods nginx-pod -o jsonpath='{.spec.containers[0].image}'` == "nginx:alpine" ] &&
          [ `kubectl get pods nginx-pod -o jsonpath='{.metadata.labels.app}'` == "nginx" ]
        foreground: |
          clear && echo -n "Preparing Environment " && until $(kubectl get componentstatus >/dev/null 2>&1); do echo -n .; sleep 1; done; echo; history -c
        courseData: 
      - title: A Pod with Multiple Containers
        task: |
          Create a pod called `multi-pod` with two containers. 

          **Container 1**:
          - name: `alpha`
          - image: `nginx:alpine`
          - environment variables: type=main

          **Container 2**:
          - name: `beta`
          - image: `busybox`
          - environment variables: type=sidecar
          - command: `sleep 4800`
        verify: |
          [ `kubectl get po multi-pod -o jsonpath='{.status.phase}'` == "Running" ] &&
          [ `kubectl get po multi-pod -o jsonpath='{.spec.containers[0].name}'` == "alpha" ] &&
          [ `kubectl get po multi-pod -o jsonpath='{.spec.containers[0].image}'` == "nginx:alpine" ] &&
          [ `kubectl get po multi-pod -o jsonpath='{.spec.containers[0].env[?(@.name=="type")].value}'` == "main" ] &&
          [ `kubectl get po multi-pod -o jsonpath='{.spec.containers[1].name}'` == "beta" ] &&
          [ `kubectl get po multi-pod -o jsonpath='{.spec.containers[1].image}'` == "busybox" ] &&
          [ `kubectl get po multi-pod -o jsonpath='{.spec.containers[1].env[?(@.name=="type")].value}'` == "sidecar" ] &&
          [ "`kubectl get po multi-pod -o jsonpath='{.spec.containers[1].command}'`" == "[sleep 4800]" ]
      - title: Failed Web Service
        task: |
          A new Pod `web` has been deployed. It failed. 
          Please fix it.

          Requirements:
          - image: `nginx` v1.16 build on `alpine`
          - pod should be running
        verify: |
          [ `kubectl get pods web -n webservices -o jsonpath='{.status.phase}'` == "Running" ] &&
          [ `kubectl get pods web -n webservices -o jsonpath='{.spec.containers[0].image}'` == "nginx:1.16-alpine" ]
        courseData: |
          kubectl create ns webservices
          kubectl run web --image=nginx:alpine-1.16 --generator=run-pod/v1 -n webservices
      - title: Failed Redis DB
        task: |
          A new Pod `redis-db` has been deployed. It failed. 
          Please fix it.
        verify: |
          [ `kubectl get pods -n db redis-db -o jsonpath='{.status.phase}'` == "Running" ] &&
          [ `kubectl get pods -n db redis-db -o jsonpath='{.spec.initContainers[0].command[0]}'` == "sleep" ] &&
          [ `kubectl get pods -n db redis-db -o jsonpath='{.spec.initContainers[0].image}'` == "busybox" ] &&
          [ `kubectl get pods -n db redis-db -o jsonpath='{.spec.containers[0].image}'` == "redis:alpine" ]
        courseData: |
          kubectl create ns db
          cat << EOF | kubectl apply -n db -f -
          apiVersion: v1
          kind: Pod
          metadata:
            name: redis-db
          spec:
            containers:
            - image: redis:alpine
              name: redis-db
            initContainers:
            - image: busybox
              name: starter
              command: 
              - s1eep
              - "10"
            restartPolicy: Never
          EOF
    intro: |
      # In this section you will do following:

      - working with Pods

      # Good Luck!
    finish: |
      # It's Done!

      Some useful commands to know:

      <pre class="file">

      kubectl run web --image=httpd --generator=run-pod/v1
      kubectl run web --image=httpd --generator=run-pod/v1 --dry-run -o yaml
      kubectl label pod app=web

      kubectl describe pod web
      kubectl get pod web -o yaml
      </pre>
    environment:
      hideintro: false
      showdashboards: true
      uilayout: terminal-iframe
      imageid: "kubernetes-cluster"
      dashboards:
        - name: User
          port: 8080
  - course_id: k8s-deployments
    title: Deployment Game
    description: Managing Deployments and all about them
    time: 45 minutes
    steps:
      - title: Welcome!
        task: |
          ## Let us know who you are.

          Please open "**User**" Tab and fill required information

          `touch /.ok`
        verify: |
          [ -f /opt/.user ]
      - title: Simple Deployment
        task: |
          Create a new deployment called `nginx-deploy`:

          Requirements:
          - name: nginx-deploy
          - image: nginx:1.16-alpine
          - replicas: 1
          - make sure that deployment and pod are running
        verify: |
          [ `kubectl get deployment nginx-deploy -o jsonpath='{.metadata.name}'` == "nginx-deploy" ] && 
          [ `kubectl get deployment nginx-deploy -o jsonpath='{.spec.template.spec.containers[0].image}'` == "nginx:1.16-alpine" ] && 
          [ `kubectl get deployment nginx-deploy -o jsonpath='{.spec.replicas}'` == 1 ] &&
          [ `kubectl get deployment nginx-deploy -o jsonpath='{.status.readyReplicas}'` == 1 ]
      - title: Rolling update
        task: |
          Record current version of `nginx-deploy` deployment. Use rolling upgrade to provide it with the `1.17` version of `nginx:alpine`. Make sure, that both `1.16` and `1.17` versions are in the rollout history. Then, rollback to `1.16` version

          Requirements:
          - deployment image is `nginx:1.16-alpine`
          - deployment has been upgraded to version `1.17-alpine` using rolling update
          - upgraded version is recorded in the resource annotation
          - deployment has been rollbacked to version `1.16`
        verify: |
          [ `kubectl get deployment nginx-deploy -o jsonpath='{.spec.template.spec.containers[0].image}'` == "nginx:1.16-alpine" ] && 
          [ `kubectl rollout history deployment nginx-deploy | grep -c "nginx=nginx:1.16-alpine"` -ge 1 ] && 
          [ `kubectl rollout history deployment nginx-deploy | grep -c "nginx=nginx:1.17-alpine"` -ge 1 ] &&
          [ `kubectl rollout history deployment nginx-deploy | grep -c "set image"` -ge 2 ]
      - title: Broken deployment
        task: |
          New deployment has been created, but it doesn't work properly. Find out and fix the issue.

          Requirements:
          - deployment "orange" is running
          - pod, associated with this deployment, is up and running
          - pod waits for 10 seconds before creating a container
        courseData: |
          kubectl create ns orange &&
          cat << EOF | kubectl apply -n orange -f -
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            namespace: orange
            labels:
              run: orange
            name: orange
          spec:
            replicas: 2
            selector:
              matchLabels:
                run: orange
            template:
              metadata:
                labels:
                  run: orange
              spec:
                containers:
                - image: nginx
                  name: orange
                initContainers:
                - image: busybox:latest-alpine
                  name: busybox
                  command:
                  - sleep
                  - 10
          EOF
        verify: |
          [ `kubectl get deployment orange -n orange -o jsonpath='{.metadata.name}'` == "orange" ] && 
          [ `kubectl get deployment orange -n orange -o jsonpath='{.spec.template.spec.containers[0].image}'` == "nginx" ] && 
          [ `kubectl get deployment orange -n orange -o jsonpath='{.spec.replicas}'` == 2 ] &&
          [ `kubectl get deployment orange -n orange -o jsonpath='{.status.readyReplicas}'` == 2 ] &&
          [ `kubectl get deployment orange -n orange -o jsonpath='{.spec.template.spec.initContainers[0].image}'` == "busybox:latest" ] &&
          [ `kubectl get deployment orange -n orange -o jsonpath='{.spec.template.spec.initContainers[0].command[1]}'` == 10 ]
      - title: Managing replicas
        task: |
          New deployment has been created, but there are no `replcaSet`s associated with it. Find out and fix the issue

          Requirements:
          - deployment `lemon` is up and running
          - deployment has 1 `replicaSet` associated with it
          - there are 3 pods managed by this replicaSet
        courseData: |
          kubectl create ns lemon &&
          cat << EOF | kubectl apply -n lemon -f -
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            namespace: lemon
            labels:
              run: lemon
            name: lemon
          spec:
            replicas: 0
            selector:
              matchLabels:
                run: lemon
            template:
              metadata:
                labels:
                  run: lemon
              spec:
                containers:
                - image: nginx
                  name: lemon
          EOF
        foreground: 
        verify: |
          [ `kubectl get deployment lemon -n lemon -o jsonpath='{.metadata.name}'` == "lemon" ] && 
          [ `kubectl get deployment lemon -n lemon -o jsonpath='{.spec.template.spec.containers[0].image}'` == "nginx" ] && 
          [ `kubectl get deployment lemon -n lemon -o jsonpath='{.spec.replicas}'` == 3 ] &&
          [ `kubectl get deployment lemon -n lemon -o jsonpath='{.status.readyReplicas}'` == 3 ]
    intro:
      # In this section you will do following:

      - working with deployment

      # Good Luck!
    finish: |
      # It's Done!

      Some useful commands to know:

      <pre class="file">

      kubectl run web --image=httpd --generator=run-pod/v1
      kubectl run web --image=httpd --generator=run-pod/v1 --dry-run -o yaml
      kubectl label pod app=web

      kubectl describe pod web
      kubectl get pod web -o yaml
      </pre>
    environment:
      hideintro: false
      showdashboards: true
      uilayout: terminal-iframe
      imageid: "kubernetes-cluster"
      dashboards:
        - name: User
          port: 8080
  - course_id: k8s-volumes
    title: Volumes Game
    description: Managing Volumes and all about them
    time: 40 minutes
    steps:
      - title: Welcome
        task: |-
          ## Let us know who you are.

          Please open "**User**" Tab and fill required information

          `touch /.ok`
        verify: |-
          [ -f /opt/.user ]
      - title: Quiz
        task: |
          Examine existing persistent volumes and answer the questions below:

          >>Q1. Enter the number of persistent volumes<<
          === 5

          >>Q2. Enter the size of biggest volume<<
          () 20
          () 30
          () 5
          (*) 10
        courseData: |
          mkdir -p /opt/data{1..5}
          cat << EOF | kubectl apply -f -
          apiVersion: v1
          kind: PersistentVolume
          metadata:
            name: pv-first
            labels:
              type: local
          spec:
            storageClassName: manual
            capacity:
              storage: 10Mi
            accessModes:
              - ReadWriteOnce
            hostPath:
              path: "/opt/data1"
          EOF

          cat << EOF | kubectl apply -f -
          apiVersion: v1
          kind: PersistentVolume
          metadata:
            name: pv-second
            labels:
              type: local
          spec:
            storageClassName: manual
            capacity:
              storage: 10Mi
            accessModes:
              - ReadWriteOnce
            hostPath:
              path: "/opt/data2"
          EOF

          cat << EOF | kubectl apply -f -
          apiVersion: v1
          kind: PersistentVolume
          metadata:
            name: pv-third
            labels:
              type: local
          spec:
            storageClassName: manual
            capacity:
              storage: 10Mi
            accessModes:
              - ReadWriteOnce
            hostPath:
              path: "/opt/data3"
          EOF

          cat << EOF | kubectl apply -f -
          apiVersion: v1
          kind: PersistentVolume
          metadata:
            name: pv-fourth
            labels:
              type: local
          spec:
            storageClassName: manual
            capacity:
              storage: 10Mi
            accessModes:
              - ReadWriteOnce
            hostPath:
              path: "/opt/data4"
          EOF

          cat << EOF | kubectl apply -f -
          apiVersion: v1
          kind: PersistentVolume
          metadata:
            name: pv-fifth
            labels:
              type: local
          spec:
            storageClassName: manual
            capacity:
              storage: 10Mi
            accessModes:
              - ReadWriteOnce
            hostPath:
              path: "/opt/data5"
          EOF
        foreground: |
          clear && echo -n "Prepairing kubelet" && 
          until $(kubelet --version >/dev/null 2>&1); do echo -n .; sleep 1; done; echo "\nWaiting for master to join" &&
          until $(kubectl get componentstatus > /dev/null 2>&1); do echo -n .; sleep 1; done; echo "\nWaiting for master to get ready" &&
          while $([ `kubectl get node master -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}'` == "False" ]); do echo -n .; sleep 1; done; echo; history -c; clear; echo "Time to rock!"
      - title: Pod
        task: |
          Create 30 Mi persistent volume `pv-first`. Create claim `pvc-first` which will bound this volume. Attach created volume to pod `nginx-pod` with image `nginx:mainline-perl`.

          Requirements:
          - pod `nginx-pod` uses proper image
          - pod mounts volume to `/opt`
          - volume `pv-first` is mounted to `nginx-pod` 
          - volume `pv-first` uses host path `/opt/data1`
          - volume `pv-first` has reclaim policy `Reatin` and access mode `ReadWriteOnce`
        verify: |
          [ `kubectl get pod nginx-pod -o jsonpath='{.spec.containers[0].image}'` == "nginx:mainline-perl" ] && 
          [ `kubectl get pv pv-first -o jsonpath='{.metadata.name}'` == "pv-first" ] &&
          [ `kubectl get pv pv-first -o jsonpath='{.spec.persistentVolumeReclaimPolicy}'` == "Retain" ] &&
          [ `kubectl get pv pv-first -o jsonpath='{.spec.accessModes}'` == "ReadWriteOnce" ] &&
          [ `kubectl get pv pv-first -o jsonpath='{.status.phase}'` == "Bound" ] &&
          [ `kubectl get pv pv-first -o jsonpath='{.spec.hostPath.path}'` == "/opt/data1" ] &&
          [ `kubectl get pv pv-first -o jsonpath='{.spec.capacity.storage}'` == "10Mi" ] &&
          [ `kubectl get pvc pvc-first -o jsonpath='{.metadata.name}'` == "pvc-first" ] &&
          [ `kubectl get pod nginx-pod -o jsonpath='{.spec.volumes[0].persistentVolumeClaim.claimName}'` == "pvc-first" ]
    intro: |
      # In this section you will do following:

      - working with volumes

      # Good Luck!
    finish: |
      # It's Done!

      Some useful commands to know:

      <pre class="file">

      kubectl run web --image=httpd --generator=run-pod/v1
      kubectl run web --image=httpd --generator=run-pod/v1 --dry-run -o yaml
      kubectl label pod app=web

      kubectl describe pod web
      kubectl get pod web -o yaml
      </pre>
    environment:
      hideintro: false
      showdashboards: true
      uilayout: terminal-iframe
      imageid: "kubernetes-cluster"
      dashboards:
        - name: User
          port: 8080
  - course_id: k8s-services
    title: Services
    description: Services in Kubernetes
    time: 45 minutes
    steps:
      - title: Welcome
        task: |-
          ## Let us know who you are.

          Please open "**User**" Tab and fill required information

          `touch /.ok`
        verify: |-
          [ -f /opt/.user ]
      - title: Services in different namespaces
        task: |-
          Examine the services in cluster and answer the questions below.

          >>Q1: Enter the number of services in default namespace<<
          === 1

          >>Q2: What name of the service?<<
          === kubernetes

          >>Q3: What type of the service?<<
          === ClusterIP



          >>Q4: How many services are there in all namespaces<<
          === 5

          >>Q5: What types of ports are there in "red" namespace<<
          [*] LoadBalancer
          [ ] TelePort
          [*] ClusterIP
          [*] NodePort 

          >>Q6: What the nodePort of "red-cluster-svc" service?<<
          ( ) 6443
          ( ) 32435
          (*) service doesn't have nodePort
          ( ) 31200

          >>Q7: What the nodePort of "red-node-svc" service?<<
          ( ) 6443
          ( ) 32435
          ( ) service doesn't have nodePort
          (*) 31200

          >>Q8: What the targetPort of "red-lb-svc" service?<<
          (*) 8000
          ( ) 32435
          ( ) service doesn't have targetPort
          ( ) 31200

          >>Q9: What the selector does "red-cluster-svc" service have?<<
          (*) app: red-pod
          ( ) run: red-pod
          ( ) app: red-cluster-svc
          ( ) run: red-cluster-svc


          ## Documentation:
          - https://kubernetes.io/docs/concepts/services-networking/service/
        courseData: |-
          kubectl create ns red

          cat << EOF | kubectl apply -f-
          apiVersion: v1
          kind: Service
          metadata:
            name: red-cluster-svc
            namespace: red
          spec:
            type: ClusterIP
            selector:
              app: red-pod
            ports:
              - port: 80
          EOF

          cat << EOF | kubectl apply -f-
          apiVersion: v1
          kind: Service
          metadata:
            name: red-node-svc
            namespace: red
          spec:
            type: NodePort
            selector:
              app: red-pod
            ports:
              - port: 8080
                targetPort: 80
                nodePort: 31200
          EOF

          cat << EOF | kubectl apply -f-
          apiVersion: v1
          kind: Service
          metadata:
            name: red-lb-svc
            namespace: red
          spec:
            type: LoadBalancer
            selector:
              app: red-pod
            ports:
              - port: 80
                targetPort: 8000
          EOF

        foreground: |-
          clear && echo -n "Prepairing Environment " && until $(kubectl get componentstatus >/dev/null 2>&1); do echo -n .; sleep 1; done; echo; history -c
        verify: |-
          [[ $(cat /tmp/secrets_default) == '1' ]]
      - title: Exposing Pods. Create Pod
        task: |-
          Create a Pod with the following parameters:

          - Pod name: `green-pod`
          - namespace: `default`
          - Pod image: `nginx`
          - Pod should have port with parameters:
            - name: `nginx-port`
            - container port: `80`
          - label: `app: green-pod`
          - make sure Pod has `Running` state

          ## Documentation:
          - https://kubernetes.io/docs/concepts/services-networking/service/
        courseData: |-
          kubectl create ns safe &&
          for item in {1..5}; do
            cat << EOF | kubectl apply --namespace=safe -f-
          apiVersion: v1
          kind: Secret
          metadata:
            name: recipe${item}
          type: Opaque
          data:
            author: $(echo -n 'https://www.youtube.com/watch?v=dQw4w9WgXcQ' | base64 -w0)
            ingridients: $(echo -n "flour_sugar_and_${item}_apples" | base64 -w0)
          EOF
          done
        verify: |-
          [[ $(kubectl get pods green-pod -o jsonpath='{.status.phase}') == 'Running' ]] &&
          [[ $(kubectl get pods green-pod -o jsonpath='{.metadata.labels.app}') == "green-pod" ]] &&
          [[ $(kubectl get pods green-pod -o jsonpath='{.spec.containers[?(@.image=="nginx")].ports[?(@.name=="nginx-port")].containerPort}') == '80' ]]
      - title: Exposing Pods. Expose Pod
        task: |-
          Using `kubectl` expose the `green-pod` with following parameters:

          - service name: `green-svc`
          - type: `NodePort`


          ## Documentation:
          - https://kubernetes.io/docs/concepts/services-networking/service/
        verify: |-
          [[ $(kubectl get svc green-svc -o jsonpath='{.spec.type}') == 'NodePort' ]] &&
          [[ $(kubectl get svc green-svc -o jsonpath='{.spec.selector.app}') == 'green-pod' ]] &&
          [[ $(kubectl get svc green-svc -o jsonpath='{.spec.ports[].targetPort}') == '80' ]]
      - title: Exposing Pods. Checking
        task: |-
          Find out the `nodePort` value of `green-svc` service.  
          Go to the `Green` tab and enter the nodePort value into box.  

          Make sure start page of nginx is available.  


          Moreover, you can reach nginx page with curl:  
          `curl hostIP:nodePort`  
          where `hostIP` is from `.status.hostIP` section of our Pod (`green-pod`)  
                `nodePort` the value from `green-svc` service.  

          Try to execute it.


          ## Documentation:
          - https://kubernetes.io/docs/concepts/services-networking/service/
      - title: Manually service creating
        task: |-
          Using `yaml` definition create another service which will be exposing `green-pod` Pod with the following requirements:

          - namespace: `default`
          - service name: `green-svc-2`
          - selector: `app: green-pod`
          - type: `NodePort`
          - nodePort: 32005


          ## Documentation:
          - https://kubernetes.io/docs/concepts/services-networking/service/
        verify: |-
          [[ $(kubectl get svc green-svc-2 -o jsonpath='{.spec.type}') == 'NodePort' ]] &&
          [[ $(kubectl get svc green-svc-2 -o jsonpath='{.spec.selector.app}') == 'green-pod' ]] &&
          [[ $(kubectl get svc green-svc-2 -o jsonpath='{.spec.ports[].targetPort}') == '80' ]] &&
          [[ $(kubectl get svc green-svc-2 -o jsonpath='{.spec.ports[].nodePort}') == '32005' ]]
      - title: Manually service creating. Checking
        task: |-
          Go to the `Green` tab again and enter the earlier set nodePort value into box. (click refresh button in tab title for reset to default port)  

          Make sure start page of nginx is available again.  


          Moreover, you can reach nginx page with curl:  
          `curl hostIP:nodePort`  
          where `hostIP` is from `.status.hostIP` section of our Pod (`green-pod`)  
                `nodePort` the value from `green-svc-2` service.  
          Try to execute it.


          ## Documentation:
          - https://kubernetes.io/docs/concepts/services-networking/service/
      - title: Exposing service to another site
        task: |-
          Create service which will make redirecting to `tut.by` site.

          Requirements:
          - service nodePort: 32500

          For self-cheking open `tut.by` tab. You should see `tut.by` homepage.



          ## Documentation:
          - https://kubernetes.io/docs/concepts/services-networking/service/
        verify: |-
          $(curl -Ls 127.0.0.1:32500 | grep "title.*TUT.BY" >/dev/null 2>&1)
      - title: Headless service
        task: |-
          You are given a `headless-pod` Pod. Create a headless service for exposing `headless-pod`.

          Requirements:
          - service name: `headless-svc`
          - namespace: `headless`

          For self-checking run another pod with `centos` image and try to get content of `headless-pod`:  
          `curl headless-svc.headless.svc.cluster.local`  

          You should see nginx default page.


          ## Documentation:
          - https://kubernetes.io/docs/concepts/services-networking/service/
        courseData: |-
          kubectl create namespace headless
          cat << EOF | kubectl apply -f-
          apiVersion: v1
          kind: Pod
          metadata:
            labels:
              app: headless-pod
            name: headless-pod
            namespace: headless
          spec:
            containers:
            - image: nginx
              name: headless-pod
              ports:
              - name: headless-port
                containerPort: 80
          EOF
        foreground: |-
          clear && echo -n "Prepairing Environment " && sleep 5 && until [[ $(kubectl get pods -n headless headless-pod -o jsonpath='{.status.phase}') == 'Running' ]]; do echo -n .; sleep 1; done; echo; history -c
        verify: |-
          [[ $(kubectl get svc -n headless headless-svc -o jsonpath='{.spec.selector.app}') == 'headless-pod' ]] &&
          [[ $(kubectl get svc -n headless headless-svc -o jsonpath='{.spec.ports[].targetPort}') == '80' ]]
      - title: Troubleshooting
        task: |
          You are given the `trouble-dep` deployment and `trouble-svc` service which should expose that deployment. But something with the service went wrong. Find and correct mistakes.  
          For self-checking use `Trouble` tab. You should see nginx default page from `troule-dep`.  
          ## Documentation:
          - https://kubernetes.io/docs/concepts/services-networking/service/
        courseData: |
          kubectl create namespace trouble
          kubectl run trouble-dep --namespace=trouble --image=nginx --restart=Always --replicas=3 --labels="app=trouble"
          cat << EOF | kubectl apply -f-
          apiVersion: v1
          kind: Service
          metadata:
            name: trouble-svc
            namespace: default
          spec:
            type: NodePort
            ports:
              - nodePort: 32200
                protocol: TCP
                port: 80
          EOF
        foreground: |
          clear && echo -n "Prepairing Environment " && sleep 5 && until [[ $(kubectl get deployments -n trouble trouble-dep | awk 'FNR==2 {print $2}') == '3/3' ]]; do echo -n .; sleep 1; done; echo; history -c
        verify: |
          [[ $(kubectl get svc -n trouble trouble-svc -o jsonpath='{.spec.selector.app}') == 'trouble' ]]
    intro: |
      # In this section you will do following:

      - explore services in different namespaces
      - find out services parameters
      - expose Pods/Deployments with services
      - make service which redirects to external site
      - make headless service
      - troubleshoot services


      # Good Luck!
    finish: |
      # It's Done!

      Some useful commands to know:

      <pre class="file">

      kubectl get services
      kubectl get services --all-namespaces
      kubectl get services -n <namespaceName>

      kubectl expose pod green-pod --name=green-svc --target-port=80 --type=NodePort
      kubectl expose deployment green-dep --name=green-svc-2 --target-port=80 --type=LoadBalancer


      </pre>
    environment:
      hideintro: false
      showdashboards: true
      uilayout: terminal-iframe
      imageid: "kubernetes-cluster"
      dashboards:
        - name: User
          port: 8080
        - name: Green
          port: 32000
        - name: tut.by
          port: 32500
        - name: Trouble
          port: 32200
  - course_id: k8s-secrets
    title: Secrets in Kubernetes
    description: Working with secrets in Kubernetes
    time: 40 minutes
    steps:
      - title: Welcome
        task: |-
          ## Let us know who you are.

          Please open "**User**" Tab and fill required information

          `touch /.ok`
        verify: |-
          [ -f /opt/.user ]
      - title: Secrets in default namespace
        task: |
          Examine the secrets in `default` namespace and answer the questions below.

          >>Q1: Enter the number of secrets in default namespace<<
          === 1

          >>Q2: Enter the type of secret(s) in default namespace<<
          === kubernetes.io/service-account-token

          >>Q3: The secret has three fields in "data" section. What of the following is redundant?
          () namespace
          () token
          (*) cluster
          () ca.crt


          ## Documentation:
          - https://kubernetes.io/docs/concepts/configuration/secret/
        foreground: |
          clear && echo -n "Prepairing Environment " && until $(kubectl get componentstatus >/dev/null 2>&1); do echo -n .; sleep 1; done; echo; history -c
        verify: |
          [[ $(cat /tmp/secrets_default) == '1' ]]
      - title: Secrets in other namespaces
        task: |
          Examine the secrets in `safe` namespace and answer the questions below.

          >>Q1: Enter the number of secrets in safe namespace<<
          === 6

          >>Q2: Enter the type of recipe* secret(s) in safe namespace<<
          === Opaque

          >>Q3: Examine and decode the content of ingridients field in data section of recipe5 secret<<
          === flour_sugar_and_5_apples


          ## Documentation:
          - https://kubernetes.io/docs/concepts/configuration/secret/
        courseData: |
          kubectl create ns safe &&
          for item in {1..5}; do
            cat << EOF | kubectl apply --namespace=safe -f-
          apiVersion: v1
          kind: Secret
          metadata:
            name: recipe${item}
          type: Opaque
          data:
            author: $(echo -n 'https://www.youtube.com/watch?v=dQw4w9WgXcQ' | base64 -w0)
            ingridients: $(echo -n "flour_sugar_and_${item}_apples" | base64 -w0)
          EOF
          done
        foreground: |
          clear && echo -n "Prepairing Environment " && until $(kubectl get secrets -n safe recipe5 >/dev/null 2>&1); do echo -n .; sleep 1; done; echo; history -c
        verify: |
          [[ $(cat /tmp/secrets_safe) == '6' ]]
      - title: Creating secrets from files
        task: |
          You are given `username_file` and `password_file` in `/data` directory. With `kubectl` create a secret using these files.

          ## Requiremets
          - secret name: `admin-secret`
          - namespace: `default`
          - from files: `/data/username_file`, `password_file`

          ## Documentation:
          - https://kubernetes.io/docs/concepts/configuration/secret/
        courseData: |
          mkdir /data &&
          echo "superhacker.$(hostname -I | awk '{print $1}')" > /data/username_file &&
          echo "verystrongpassword.$(hostname -I | awk '{print $1}')" > /data/password_file
        foreground: |
          clear && echo -n "Prepairing Environment " && until $([ -f "/data/username_file" ] && [ -f "/data/password_file" ]); do echo -n .; sleep 1; done; echo; history -c
        verify: |
          [[ $(kubectl get secrets admin-secret -o yaml -o jsonpath='{.data.username_file}' | base64 -d) == $(cat /data/username_file) ]] &&
          [[ $(kubectl get secrets admin-secret -o yaml -o jsonpath='{.data.password_file}' | base64 -d) == $(cat /data/password_file) ]]
      - title: Secrets creating
        task: |
          Create a simple secret with the following requirements:

          ## Requirements
          - secret name: `devops-secret`
          - namespace: `default`
          - type: `Opaque`
          - `username` field: `devops`
          - `password` field: `devops_password`
          - `email` field: `devops@devops.dev`
          - all string data schould be encoded (using base64)


          ## Documentation:
          - https://kubernetes.io/docs/concepts/configuration/secret/
        verify: |
          [[ $(kubectl get secrets devops-secret -o yaml -o jsonpath='{.data.username}' | base64 -d) == "devops" ]] &&
          [[ $(kubectl get secrets devops-secret -o yaml -o jsonpath='{.data.password}' | base64 -d) == "devops_password" ]] &&
          [[ $(kubectl get secrets devops-secret -o yaml -o jsonpath='{.data.email}' | base64 -d) == "devops@devops.dev" ]]
      - title: Secrets in environvent variables
        task: |
          Create a simple pod with name `email-pod` which get only `email` field from `devops-secret` as environment variable with name `EMAIL`:

          ## Requirements
          - namespace: `default`
          - pod name: `email-pod`
          - image: `busybox`
          - comand: `sleep 4800`
          - pod should have env variable `EMAIL` with value from `devops-secret` secret

          ## Documentation:
          - https://kubernetes.io/docs/concepts/configuration/secret/
        verify: |
          [[ $(kubectl get pods email-pod -o jsonpath='{.status.phase}') == "Running" ]] &&
          [[ $(kubectl get pods email-pod -o jsonpath='{.spec.containers[?(@.name=="email-pod")].image}') == "busybox" ]] &&
          [[ $(kubectl get pods email-pod -o jsonpath='{.spec.containers[?(@.name=="email-pod")].env[?(@.name=="EMAIL")].valueFrom.secretKeyRef.name}') == "devops-secret" ]] &&
          [[ $(kubectl get pods email-pod -o jsonpath='{.spec.containers[?(@.name=="email-pod")].env[?(@.name=="EMAIL")].valueFrom.secretKeyRef.key}') == "email" ]]
      - title: Secrets in environment variables 2
        task: |
          Create a simple pod with name `dev-pod` which get all fields from `devops-secret` as environment variable with names `USERNAME`, `PASSWORD`, `EMAIL` correspondingly.

          ## Requirements
          - namespace: `default`
          - pod name: `dev-pod`
          - image: `busybox`
          - command: `sleep 4800`
          - pod should have env variables `USERNAME`, `PASSWORD`, `EMAIL` with values from `devops-secret` secret correspondingly (hint: envFrom).

          ## Documentation:
          - https://kubernetes.io/docs/concepts/configuration/secret/
        verify: |
          [[ $(kubectl get pods dev-pod -o jsonpath='{.status.phase}') == "Running" ]] &&
          [[ $(kubectl get pods dev-pod -o jsonpath='{.spec.containers[?(@.name=="dev-pod")].image}') == "busybox" ]] &&
          [[ $(kubectl get pods dev-pod -o jsonpath='{.spec.containers[?(@.name=="dev-pod")].envFrom[0].secretRef.name}') == "devops-secret" ]]
      - title: Secrets as volume
        task: |
          Create a simple pod with name `dev-volume-pod` which will use `devops-secret` secret as volume.

          ## Requirements
          - namespace: `default`
          - pod name: `dev-volume-pod`
          - image: `busybox`
          - command: `sleep 3600`
          - pod should use `devops-secret` as attached volume
          - volume name: `devops-volume`
          - mountPath: `/etc/devops-secret`

          ## Documentation:
          - https://kubernetes.io/docs/concepts/configuration/secret/
        verify: |
          [[ $(kubectl get pods dev-volume-pod -o jsonpath='{.status.phase}') == "Running" ]] &&
          [[ $(kubectl get pods dev-volume-pod -o jsonpath='{.spec.containers[?(@.name=="dev-volume-pod")].image}') == "busybox" ]] &&
          [[ $(kubectl get pods dev-volume-pod -o jsonpath='{.spec.volumes[?(@.name=="devops-volume")].secret.secretName}') == "devops-secret" ]] &&
          [[ $(kubectl get pods dev-volume-pod -o jsonpath='{.spec.containers[?(@.name=="dev-volume-pod")].volumeMounts[?(@.name=="devops-volume")].mountPath}') == "/etc/devops-secret" ]]
    intro: 
    finish: 
    environment:
      hideintro: false
      showdashboards: true
      uilayout: terminal-iframe
      imageid: "kubernetes-cluster"
      dashboards:
        - name: User
          port: 8080
  - course_id: k8s-configmaps
    title: ConfigMaps in Kubernetes
    description: Working with ConfigMaps in Kubernetes
    time: 40 minutes
    steps:
      - title: Welcome
        task: |-
          ## Let us know who you are.

          Please open "**User**" Tab and fill required information

          `touch /.ok`
        verify: |-
          [ -f /opt/.user ]
      - title: Configmaps in different namespaces
        task: |
          Examine the ConfigMaps in cluster and answer the questions below.

          >>Q1: Enter the number of ConfigMaps in default namespace<<
          === 0

          >>Q2: Enter the number of ConfigMaps in all namespaces<<
          === 12

          >>Q3: Enter the number of ConfigMaps in "safe" namespace<<
          === 5

          >>Q4: What data is safed in "ingridients" field of "recipe3" ConfigMap?<<
          === flour_sugar_and_3_apples

          >>Q5: Find out "dnsDomain" value of cluster in "kubeadm-config" ConfigMap<<
          === cluster.local

          >>Q6: ConfigMaps can store yaml definitions as data. (hint: explore ClusterConfiguration in "kubeadm-config" ConfigMap)<<
          (*) True
          ( ) False



          ## Documentation:
          - https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/
        foreground: |
          clear && echo -n "Prepairing Environment " && until $(kubectl get configmaps -n safe recipe5 >/dev/null 2>&1); do echo -n .; sleep 1; done; echo; history -c
        courseData: |
          kubectl create ns safe &&
          for item in {1..5}; do
            cat << EOF | kubectl apply -f-
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: recipe${item}
            namespace: safe
          data:
            author: devops-${item}th
            ingridients: flour_sugar_and_${item}_apples
          EOF


          done 
      - title: Creating ConfigMaps from files
        task: |
          You are given `/data/data_file` file. With `kubectl` create a secret using that file.

          ## Requiremets
          - ConfigMap name: `os-config`
          - namespace: `default`
          - from files: `/data/data_file`

          ## Documentation:
          - https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/
        courseData: |
          mkdir /data &&
          echo "IP=$(hostname -I | awk '{print $1}')" > /data/data_file &&
          echo "$(cat /etc/os-release | awk 'FNR==1')" >> /data/data_file &&
          echo "$(cat /etc/os-release | awk 'FNR==2')" >> /data/data_file &&
          echo "$(cat /etc/os-release | awk 'FNR==5')" >> /data/data_file
        foreground: |
          clear && echo -n "Prepairing Environment " && until $([ -f "/data/data_file" ]); do echo -n .; sleep 1; done; echo; history -c
        verify: |
          [[ $(kubectl get configmaps os-config -o jsonpath='{.data.data_file}' | awk 'FNR==2') == $(cat /etc/os-release | awk 'FNR==1') ]]
      - title: ConfigMaps creating
        task: |
          Create a simple ConfigMap with the following requirements:

          ## Requirements
          - ConfigMap name: `users-cm`
          - namespace: `default`
          - data field:
            - `cluster-admin` field: `admin`
            - `devops` field: `devops`
            - `db-admin` field: `db-admin`
            - `user1` field: `Jack`
            - `user2` field: `John`

          ## Documentation:
          https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/
        verify: |
          [[ $(kubectl get configmaps users-cm -o jsonpath='{.data.cluster-admin}') == "admin" ]] &&
          [[ $(kubectl get configmaps users-cm -o jsonpath='{.data.devops}') == "devops" ]] &&
          [[ $(kubectl get configmaps users-cm -o jsonpath='{.data.db-admin}') == "db-admin" ]] &&
          [[ $(kubectl get configmaps users-cm -o jsonpath='{.data.user1}') == "Jack" ]] &&
          [[ $(kubectl get configmaps users-cm -o jsonpath='{.data.user2}') == "John" ]]
      - title: ConfigMaps in environvent variables
        task: |
          Create a simple pod with name `user-pod` which get only `user1` and `user2` fields from `users-cm` as environment variable with names `USER1` and `USER2` correspondingly:

          ## Requirements
          - namespace: `default`
          - pod name: `user-pod`
          - image: `busybox`
          - comand: `sleep 4800`
          - pod should have env variable `USER1` with value from `user1` field of `users-cm` ConfigMap
          - pod should have env variable `USER2` with value from `user2` field of `users-cm` ConfigMap
          - other values shouldn't be in env variables of `user-pod`

          ## Documentation:
          - https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/

        verify: |
          [[ $(kubectl get pods user-pod -o jsonpath='{.status.phase}') == "Running" ]] &&
          [[ $(kubectl get pods user-pod -o jsonpath='{.spec.containers[].env[?(@.name=="USER1")].valueFrom.configMapKeyRef.key}') == "user1" ]] &&
          [[ $(kubectl get pods user-pod -o jsonpath='{.spec.containers[].env[?(@.name=="USER2")].valueFrom.configMapKeyRef.key}') == "user2" ]]
      - title: ConfigMaps in environment variables 2
        task: |
          Create a simple pod with name `team-pod` which get all fields from `users-cm` ConfigMap as environment variable.

          ## Requirements
          - namespace: `default`
          - pod name: `team-pod`
          - image: `busybox`
          - command: `sleep 4800`
          - pod should have env variables from all `users-cm` ConfigMap fields (hint: envFrom).

          ## Documentation:
          - https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/
        verify: |
          [[ $(kubectl get pods team-pod -o jsonpath='{.status.phase}') == "Running" ]] &&
          [[ $(kubectl get pods team-pod -o jsonpath='{.spec.containers[?(@.name=="team-pod")].image}') == "busybox" ]] &&
          [[ $(kubectl get pods team-pod -o jsonpath='{.spec.containers[?(@.name=="team-pod")].envFrom[0].configMapRef.name}') == "users-cm" ]]
      - title: ConfigMaps as volume
        task: |
          Create a simple pod with name `team-volume-pod` which will use `users-cm` ConfigMap as volume.

          ## Requirements
          - namespace: `default`
          - pod name: `team-volume-pod`
          - image: `busybox`
          - command: `sleep 3600`
          - pod should use `users-cm` ConfigMap as attached volume
          - volume name: `team-volume`
          - mountPath: `/etc/team-members`

          ## Documentation:
          - https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/

        verify: |
          [[ $(kubectl get pods team-volume-pod -o jsonpath='{.status.phase}') == "Running" ]] &&
          [[ $(kubectl get pods team-volume-pod -o jsonpath='{.spec.containers[?(@.name=="team-volume-pod")].image}') == "busybox" ]] &&
          [[ $(kubectl get pods team-volume-pod -o jsonpath='{.spec.volumes[?(@.name=="team-volume")].configMap.name}') == "users-cm" ]] &&
          [[ $(kubectl get pods team-volume-pod -o jsonpath='{.spec.containers[?(@.name=="team-volume-pod")].volumeMounts[?(@.name=="team-volume")].mountPath}') == "/etc/team-members" ]]
    intro: |
      # In this section you will do following:

      - discover ConfigMaps in different namespaces
      - create ConfigMaps
      - pass the ConfigMaps data to environment variables
      - mount ConfigMaps as volume

      # Good Luck!
    finish: |
      # It's Done!

      Some useful commands to know:

      <pre class="file">

      kubectl get configmaps
      kubectl get configmaps -n <namespace>
      kubectl get configmaps --all-namespaces

      kubectl get configmaps -n <namespace> configmapname -o yaml

      kubectl get configmaps devops-configmap -o yaml -o jsonpath='{.data.username}'   # devops

      </pre>
    environment:
      hideintro: false
      showdashboards: true
      uilayout: terminal-iframe
      imageid: "kubernetes-cluster"
      dashboards:
        - name: User
          port: 8080
  - course_id: k8s-exam-1
    title: Exam 1
    description: Exam 1
    time: 30 minutes
    steps:
      - title: Welcome
        task: |-
          ## Let us know who you are.

          Please open "**User**" Tab and fill required information

          `touch /.ok`
        verify: |-
          [ -f /opt/.user ]
      - title: Configmaps in different namespaces
        task: |
          Please create infrastructure by following requiremets:

          <details><summary><b>Namespace</b></summary><p>
          Name: ns-DzxKZMQfYr
          </p></details>


          <details><summary><b>Persistent Volumes</b></summary><p>
          Configure drupal-pv with hostPath = /drupal-data (create the directory on Worker Nodes)
          Configure drupal-mysql-pv with hostPath = /drupal-mysql-data (create the directory on Worker Nodes)
          </p></details>
    intro: |
      # Good Luck!
    finish: |
      # It's Done!
    environment:
      hideintro: false
      showdashboards: true
      uilayout: terminal-iframe
      imageid: "kubernetes-cluster"
      dashboards:
        - name: User
          port: 8080

